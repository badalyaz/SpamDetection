{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4b5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f0795",
   "metadata": {},
   "source": [
    "### Open the preprocessed data, split into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1036e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5735, 2) (638, 2) (160, 2)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/spam_preprocessed.csv\")\n",
    "test_data=pd.read_csv(\"./data/test_data.csv\")\n",
    "gen_train=pd.read_csv(\"./data/generated_train_data.csv\")\n",
    "data=pd.concat([data, gen_train], ignore_index=True).sample(frac=1).reset_index(drop=True, )\n",
    "train_data, val_data = train_test_split(data, test_size=0.1, random_state=2023)\n",
    "\n",
    "print(train_data.shape, val_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3edac2",
   "metadata": {},
   "source": [
    "### Initialize embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b03612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedding_model = BertModel.from_pretrained(\n",
    "    \"bert-base-uncased\", output_hidden_states=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8cc0d7",
   "metadata": {},
   "source": [
    "### Get embeddings from from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a2e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = create_embeddings(list(train_data[\"text\"].values), embedding_model)\n",
    "X_val = create_embeddings(list(val_data[\"text\"].values), embedding_model)\n",
    "X_test = create_embeddings(list(test_data[\"text\"].values), embedding_model)\n",
    "\n",
    "y_train = train_data[\"ham_spam_encoded\"]\n",
    "y_test = test_data[\"ham_spam_encoded\"]\n",
    "y_val = val_data[\"ham_spam_encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating fc model and weights\n",
    "model_fc = fc_model_softmax(input_num=768)\n",
    "weights_path = f\"model/model.hdf5\"  # path where will save model weights\n",
    "model_fc.save_weights(\n",
    "    weights_path\n",
    ")  \n",
    "# if we want to cancel learning and start from 0, if not comment the line\n",
    "model_fc.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5722d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining epochs count, batch size and learning rate\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = to_tf(X_test)\n",
    "X_train = to_tf(X_train)\n",
    "X_val = to_tf(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f5fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = (X_train, X_val, y_train, y_val)\n",
    "history = trainer(\n",
    "    model_fc, data, weights_path, batch_size, epochs, learning_rate=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0cf313",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, tn, fp, fn = get_metrics(model_fc, weights_path, X_test, y_test)\n",
    "\n",
    "print(f\"----- Accuracy = \\t{(tp+tn)/(tp + tn + fp + fn):.2%} -----\")\n",
    "print(f\"----- Precision = \\t{tp/(tp + fp):.2%} -----\")\n",
    "print(f\"----- Recall =  \\t{tp/(tp + fn):.2%} -----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d40491c",
   "metadata": {},
   "source": [
    "### Training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e89dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685809fd",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.array([[tn, fp], [fn, tp]])\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "class_labels = [\"ham\", \"spam\"]\n",
    "sns.heatmap(\n",
    "    confusion_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_labels,\n",
    "    yticklabels=class_labels,\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
